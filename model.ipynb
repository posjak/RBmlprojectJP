{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8c67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neptune.new as neptune\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from functools import partial\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, RegressorMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE\n",
    "\n",
    "np.random.seed(0)\n",
    "standardizer=StandardScaler()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155a3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join('data','train_data.csv'), header=None)\n",
    "y = pd.read_csv(os.path.join('data','train_labels.csv'), header=None, names=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adec3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5950d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11919106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(classifier):\n",
    "\n",
    "    m = classifier.fit(X, y)\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa1ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7956149576655805\n",
      "[[ 20 102]\n",
      " [143 860]]\n",
      "KNeighborsClassifier 0.949668992580465\n",
      "[[ 91  31]\n",
      " [ 25 978]]\n",
      "SVC 0.9539267661631968\n",
      "[[102  20]\n",
      " [ 33 970]]\n",
      "AdaBoostClassifier 0.9407824512727929\n",
      "[[ 83  39]\n",
      " [ 26 977]]\n",
      "OneClassSVM 0.5762279967887776\n",
      "[[ 52  70]\n",
      " [512 491]]\n",
      "RandomForestClassifier 0.8404419381787802\n",
      "[[   0  122]\n",
      " [   0 1003]]\n",
      "GradientBoostingClassifier 0.9643584417488882\n",
      "[[104  18]\n",
      " [ 27 976]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "log_clf = LogisticRegression(random_state=0, max_iter = 1000)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "svm_clf = SVC()\n",
    "abc_clf = AdaBoostClassifier()\n",
    "oc_clf = OneClassSVM()\n",
    "rfc_clf = RandomForestClassifier()\n",
    "gbc_clf = GradientBoostingClassifier()\n",
    "\n",
    "clf_list = [log_clf, knn_clf, svm_clf, abc_clf, oc_clf, rfc_clf, gbc_clf]\n",
    "\n",
    "def clf_scores(list):\n",
    "    for clf in list:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        clf_score = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(clf.__class__.__name__, clf_score)\n",
    "        get_confusion_matrix(clf)\n",
    "\n",
    "\n",
    "        plt.title('Scores')\n",
    "        plt.bar(clf.__class__.__name__, clf_score);\n",
    "\n",
    "clf_scores(clf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addb782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "def train_and_predict(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return f1_score(y_test, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3febb1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8404419381787802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline( [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('normalize', MinMaxScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "train_and_predict(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dd621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 0.941317263697903\n",
      "rf 0.4736842105263158\n",
      "GBC 0.87459200599283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "models = [\n",
    "    ('dt', DecisionTreeClassifier(max_depth=5, random_state=2019)),\n",
    "    ('rf', RandomForestClassifier(max_depth=5, n_estimators=20, random_state=2019)),\n",
    "    ('GBC', GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, max_depth=1, random_state=2019)),\n",
    "]\n",
    "\n",
    "for model_name, model in models:\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    score = f1_score(y, y_pred, average='macro')\n",
    "    \n",
    "    print(model_name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c94386ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No feature in X meets the variance threshold 0.05000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f292a26eab25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_and_predict_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f292a26eab25>\u001b[0m in \u001b[0;36mtrain_and_predict_f1\u001b[1;34m(model, X_train, y_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_and_predict_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jakub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\" (X contains only one sample)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No feature in X meets the variance threshold 0.05000"
     ]
    }
   ],
   "source": [
    "avg=['micro', 'macro','weighted', None]\n",
    "def train_and_predict_f1(model, X_train, y_train):\n",
    "    for x in avg:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred[ y_pred < 0 ] =0\n",
    "        print(f1_score(y, y_pred, average=x, zero_division=1))\n",
    "\n",
    "pipeline = Pipeline( [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('normalize', MinMaxScaler()),\n",
    "    ('variance-treshold', VarianceThreshold(threshold=0.05)),\n",
    "    ('model', RandomForestClassifier(max_depth=5, n_estimators=10))\n",
    "])\n",
    "\n",
    "train_and_predict_f1(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c868d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 3/3 [00:54<00:00, 18.30s/trial, best loss: 0.7795555555555556]\n",
      "The best params:  {'x_penalty': 1, 'x_solver': 0}\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    \n",
    "    lg_params = {\n",
    "        'penalty': space['penalty'],\n",
    "        'solver': space['solver']\n",
    "    }\n",
    "    \n",
    "    model = LogisticRegression(**lg_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return{'loss':score, 'status': STATUS_OK }\n",
    "penalty=list['l1','l2','elasticnet',None]\n",
    "space ={\n",
    "    'penalty': hp.choice ('x_penalty', ['l2','none']),\n",
    "    'solver': hp.choice ('x_solver', ['newton-cg', 'lbfgs', 'saga'])\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=partial(tpe.suggest, n_startup_jobs=1),\n",
    "            max_evals=3,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"The best params: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2008a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 2,\n",
       " 'spec': None,\n",
       " 'result': {'loss': 0.7795555555555556, 'status': 'ok'},\n",
       " 'misc': {'tid': 2,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'x_penalty': [2], 'x_solver': [2]},\n",
       "  'vals': {'x_penalty': [1], 'x_solver': [0]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2021, 6, 30, 17, 54, 11, 301000),\n",
       " 'refresh_time': datetime.datetime(2021, 6, 30, 17, 54, 22, 99000)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ead3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('prep', StandardScaler()), ('prep2', PCA()), ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622f22ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944522323872079"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='none',solver='newton-cg',max_iter=4100,multi_class='ovr')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae725e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 3/3 [02:34<00:00, 51.49s/trial, best loss: 0.8404419381787802]\n",
      "The best params:  {'x_max_depth': 10.0, 'x_max_features': 1, 'x_n_estimators': 300.0}\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    \n",
    "    gbc_params = {\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'max_depth': int(space['max_depth']),\n",
    "        'max_features': space['max_features']\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier(**gbc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return{'loss':score, 'status': STATUS_OK }\n",
    "space ={'n_estimators': hp.quniform ('x_n_estimators', 100, 500, 100),\n",
    "        'max_depth': hp.quniform ('x_max_depth', 3, 10, 1),\n",
    "        'max_features': hp.choice ('x_max_features', ['auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_params_gbc = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=partial(tpe.suggest, n_startup_jobs=1),\n",
    "            max_evals=3,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"The best params: \", best_params_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9918196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 3/3 [12:23<00:00, 247.92s/trial, best loss: 0.8404419381787802]\n",
      "The best params:  {'x_criterion': 0, 'x_max_features': 1, 'x_n_estimators': 300.0}\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    \n",
    "    rfc_params = {\n",
    "        'n_estimators': int(space['n_estimators']),\n",
    "        'criterion': space['criterion'],\n",
    "        'max_features': space['max_features']\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**rfc_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    \n",
    "    return{'loss':score, 'status': STATUS_OK }\n",
    "space ={'n_estimators': hp.quniform ('x_n_estimators', 200, 500, 100),\n",
    "        'criterion': hp.choice ('x_criterion', ['gini', 'entropy']),\n",
    "        'max_features': hp.choice ('x_max_features', ['auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=partial(tpe.suggest, n_startup_jobs=1),\n",
    "            max_evals=3,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"The best params: \", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
